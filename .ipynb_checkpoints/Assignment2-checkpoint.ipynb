{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a4a71e2b",
   "metadata": {},
   "source": [
    "# Assignment 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbc94574",
   "metadata": {},
   "source": [
    "## Abstract\n",
    "\n",
    "This notebook presents the construction and interpretation of an AutoML-based predictive model for Valorant player ratings. Key steps include environment setup, H2O server initialization, and data preparation, where multicollinear features are pruned to improve model reliability. The model, with a focus on the Gradient Boosting Machine (GBM), undergoes training and performance evaluation through metrics like MSE and RMSE. Results demonstrate the model's strong fit to the data. Insightful Variable Importance Plots further illuminate the predominant factors influencing player ratings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0cbaf05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: requests in c:\\users\\pende\\anaconda3\\lib\\site-packages (2.31.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\pende\\anaconda3\\lib\\site-packages (from requests) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\pende\\anaconda3\\lib\\site-packages (from requests) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\pende\\anaconda3\\lib\\site-packages (from requests) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\pende\\anaconda3\\lib\\site-packages (from requests) (2023.7.22)\n",
      "Requirement already satisfied: tabulate in c:\\users\\pende\\anaconda3\\lib\\site-packages (0.8.10)\n",
      "Requirement already satisfied: colorama>=0.3.8 in c:\\users\\pende\\anaconda3\\lib\\site-packages (0.4.6)\n"
     ]
    }
   ],
   "source": [
    "!pip install requests\n",
    "!pip install tabulate\n",
    "!pip install \"colorama>=0.3.8\"\n",
    "!pip install future"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be4e98c1",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "!pip install -f http://h2o-release.s3.amazonaws.com/h2o/latest_stable_Py.html h2o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21907fa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import h2o\n",
    "from h2o.automl import H2OAutoML\n",
    "import random, os, sys\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import logging\n",
    "import csv\n",
    "import optparse\n",
    "import time\n",
    "import json\n",
    "from distutils.util import strtobool\n",
    "import psutil\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "sns.set(context=\"notebook\", palette=\"Spectral\", style = 'darkgrid' ,font_scale = 1.5, color_codes=True)\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.compat import lzip\n",
    "import statsmodels.stats.api as sms\n",
    "from sklearn.model_selection import train_test_split as tts\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import LassoCV\n",
    "from sklearn.linear_model import RidgeCV\n",
    "from sklearn.metrics import r2_score,mean_squared_error,mean_absolute_error\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV,RandomizedSearchCV\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "from statsmodels.tools.tools import add_constant\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from h2o.estimators.glm import H2OGeneralizedLinearEstimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be4ff2d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_mem_size=6 \n",
    "run_time=222"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ba49922",
   "metadata": {},
   "outputs": [],
   "source": [
    "pct_memory=0.5\n",
    "virtual_memory=psutil.virtual_memory()\n",
    "min_mem_size=int(round(int(pct_memory*virtual_memory.available)/1073741824,0))\n",
    "print(min_mem_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb02f469",
   "metadata": {},
   "outputs": [],
   "source": [
    "port_no=random.randint(5555,55555)\n",
    "\n",
    "#  h2o.init(strict_version_check=False,min_mem_size_GB=min_mem_size,port=port_no) # start h2o\n",
    "try:\n",
    "  h2o.init(strict_version_check=False,min_mem_size_GB=min_mem_size,port=port_no) # start h2o\n",
    "except:\n",
    "  logging.critical('h2o.init')\n",
    "  h2o.download_all_logs(dirname=logs_path, filename=logfile)      \n",
    "  h2o.cluster().shutdown()\n",
    "  sys.exit(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e59058f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing the dataset to this notebook\n",
    "data = pd.read_csv(\"https://raw.githubusercontent.com/MukulSaiPendem/DSEM_Assignment_2/main/val_stats.csv\", low_memory=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc48f685",
   "metadata": {},
   "source": [
    "## DATASET DESCRIPTION\n",
    "This dataset contains data related to player performance in a competitive video game Valorant. This is a first person shooter video game. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c85f7389",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8c629bb",
   "metadata": {},
   "source": [
    "## Variable Descriptions\n",
    "\n",
    "**Region**: \n",
    "<span style=\"color:green;\">Indicates the geographical location or server region of the player. Different regions can represent different player communities and competitive environments.</span>\n",
    "\n",
    "**Name**: \n",
    "<span style=\"color:green;\">The in-game username chosen by the player. It's a unique identifier for each player within the game.</span>\n",
    "\n",
    "**Tag**: \n",
    "<span style=\"color:green;\">An additional identifier or code associated with the player's account, often used in conjunction with the name for unique identification.</span>\n",
    "\n",
    "**Rating**: \n",
    "<span style=\"color:green;\">A numerical value representing the player's skill level or rank. Higher ratings usually indicate more skilled or experienced players.</span>\n",
    "\n",
    "**Damage per Round**: \n",
    "<span style=\"color:green;\">Shows the average amount of damage the player inflicts on opponents in each round. This is a measure of the player's effectiveness in harming opponents, with higher values indicating greater impact in the game.</span>\n",
    "\n",
    "**Headshots**: \n",
    "<span style=\"color:green;\">The total number of times a player has successfully hit opponents in the head. Headshots are typically more difficult to achieve but are more effective in the game.</span>\n",
    "\n",
    "**Headshot Percent**: \n",
    "<span style=\"color:green;\">The percentage of the player's shots that result in headshots. A higher percentage is indicative of better precision and aiming skill.</span>\n",
    "\n",
    "**Kills**: \n",
    "<span style=\"color:green;\">The total number of opponents a player has eliminated. This is a direct measure of offensive performance.</span>\n",
    "\n",
    "**Deaths**: \n",
    "<span style=\"color:green;\">The number of times a player has been eliminated by an opponent. This figure is used to assess a player's survivability and defensive skills.</span>\n",
    "\n",
    "**Assists**: \n",
    "<span style=\"color:green;\">The count of assists represents the number of times a player has helped a teammate kill an opponent. Assists can indicate a player's teamwork and support capabilities.</span>\n",
    "\n",
    "**K/D Ratio**: \n",
    "<span style=\"color:green;\">The kill/death ratio is calculated by dividing the number of kills by the number of deaths. A higher ratio suggests that a player eliminates more opponents than they are eliminated.</span>\n",
    "\n",
    "**Kills per Round**: \n",
    "<span style=\"color:green;\">The average number of kills a player achieves each round, which shows their consistent contribution to the team's offensive efforts.</span>\n",
    "\n",
    "**Most Kills**: \n",
    "<span style=\"color:green;\">The highest number of kills a player has achieved in a single game. This can highlight a player's peak performance capability.</span>\n",
    "\n",
    "**Score per Round**: \n",
    "<span style=\"color:green;\">The average score a player achieves per round, factoring in various aspects of their performance, not just eliminations.</span>\n",
    "\n",
    "**Wins**: \n",
    "<span style=\"color:green;\">The number of games a player or their team has won. Wins are the ultimate objective and indicate the effectiveness of a player's contribution to the team's success.</span>\n",
    "\n",
    "**Win Percent**: \n",
    "<span style=\"color:green;\">The percentage of games won out of all games played. This metric is used to gauge overall team success and, indirectly, the player's impact on games.</span>\n",
    "\n",
    "**Aces**: \n",
    "<span style=\"color:green;\">Counts the number of times a player has single-handedly eliminated all opposing team members in a round. This is a rare and notable achievement, showcasing exceptional individual skill.</span>\n",
    "\n",
    "**Clutches**: \n",
    "<span style=\"color:green;\">The number of rounds a player wins single-handedly while being the last surviving member of their team against multiple opponents. This metric highlights the player's ability to perform under high-pressure situations.</span>\n",
    "\n",
    "**Flawless**: \n",
    "<span style=\"color:green;\">Refers to rounds where the player's team wins without losing any team members. It indicates a round dominated by the player's team.</span>\n",
    "\n",
    "**Gun Statistics**: \n",
    "<span style=\"color:green;\">These include detailed performance metrics for different guns used by players. Each gun has associated statistics like gun name, head, body, legs, and kills, providing insights into weapon proficiency and playstyle.</span>\n",
    "<span style=\"color:black;\">all theses columns come under this 'gun1_name', 'gun1_head', 'gun1_body', 'gun1_legs', 'gun1_kills', 'gun2_name', 'gun2_head', 'gun2_body', 'gun2_legs', 'gun2_kills', 'gun3_name', 'gun3_head', 'gun3_body', 'gun3_legs', 'gun3_kills'</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50e5e34a",
   "metadata": {},
   "source": [
    " ## What are the data types? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb04c4e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6dd6e14",
   "metadata": {},
   "source": [
    "Some features are wrongly classified as object dtype due to the issue with commas (,) typically arises from the way numbers are formatted in certain locales. In many places, commas are used as thousand separators to improve readability of large numbers. For example, the number one thousand is often written as 1,000."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84837daf",
   "metadata": {},
   "source": [
    "these columns have this issue\n",
    "'gun1_kills', 'gun2_kills', 'first_bloods', 'headshots', 'deaths', 'kills', 'assists'\n",
    "\n",
    "**How to correct this?**\n",
    "we need to replace the (,) with ''. this is resolve the wrong interpretation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69358927",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to safely convert columns to integers\n",
    "def convert_column_to_int(df, column_name):\n",
    "    if df[column_name].dtype == 'object':\n",
    "        df[column_name] = pd.to_numeric(df[column_name].str.replace(',', ''), errors='coerce')\n",
    "    return df\n",
    "\n",
    "# Columns that we expect to be numeric but may contain commas\n",
    "columns_with_potential_commas = ['gun1_kills', 'gun2_kills', 'first_bloods', 'headshots', 'deaths', 'kills', 'assists']\n",
    "\n",
    "# Apply the conversion to each column\n",
    "for col in columns_with_potential_commas:\n",
    "    data = convert_column_to_int(data, col)\n",
    "\n",
    "# Now check the dtypes to confirm the conversion\n",
    "data.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "848f63f0",
   "metadata": {},
   "source": [
    "## Numeric Data Types:\n",
    "\n",
    "- **Float64**: `damage_round`, `headshot_percent`, `kd_ratio`, `kills_round`, `score_round`, `win_percent`. \n",
    "  - These are floating-point numbers and can represent quantities with decimal precision.\n",
    "\n",
    "- **Int64**: `headshots`, `first_bloods`, `kills`, `deaths`, `assists`, `aces`, `clutches`, `flawless`, `most_kills`, `wins`, `gun1_head`, `gun1_body`, `gun1_legs`, `gun2_head`, `gun2_body`, `gun2_legs`, `gun3_head`, `gun3_body`, `gun3_legs`, `gun3_kills` , `gun1_kills`, `gun2_kills`. \n",
    "  - These are integer numbers and represent whole quantities without decimals.\n",
    "\n",
    "## Categorical Data Types:\n",
    "\n",
    "- **Object**: `region`, `name`, `tag`, `rating`, `assists`, `agent_1`, `agent_2`, `agent_3`, `gun1_name`, `gun2_name`, `gun3_name`. \n",
    "  - These are typically non-numeric data and are treated as categorical.\n",
    "\n",
    "As the data Size is huge, to reduce high computation time we are going to do **Sampling** on the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9615ce2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_dataset = data.sample(frac=0.2, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54aebb1c",
   "metadata": {},
   "source": [
    "## Are there missing values?\n",
    "\n",
    "Yes, there are some missing values in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1682a0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_dataset.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d7704f4",
   "metadata": {},
   "source": [
    "##  Which independent variables have missing data? How much? \n",
    "\n",
    "### Missing Values in the Dataset\n",
    "\n",
    "- `region`: 4225 missing values\n",
    "- `name`: 0 missing values\n",
    "- `tag`: 48 missing values\n",
    "- `agent_2`: 375 missing values\n",
    "- `agent_3`: 1005 missing values\n",
    "\n",
    "All other columns do not have missing values. Handling these missing values is a crucial step in the data preprocessing phase prior to any detailed analysis or predictive modeling.\n",
    "We only have missing values in 5 featues( catagorical ), all numerical feature are complete without any missing values\n",
    "\n",
    "## How can we remove the missing values?\n",
    "\n",
    "As our missing values are only from catagorical data, lets use **Mode Imputation**\n",
    "\n",
    "### Mode Imputation\n",
    "\n",
    "The method of replacing missing values in each categorical column with the most frequent value (mode) in that column is commonly referred to as \"Mode Imputation\" or \"Imputation by the Most Frequent Value.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "247bcc6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identifying categorical columns\n",
    "categorical_columns = sampled_dataset.select_dtypes(include=['object', 'category']).columns\n",
    "\n",
    "# Applying mode imputation\n",
    "for col in categorical_columns:\n",
    "    most_frequent_value = sampled_dataset[col].mode()[0]\n",
    "    sampled_dataset[col].fillna(most_frequent_value, inplace=True)\n",
    "\n",
    "# Checking for remaining null values\n",
    "print(\"Remaining null values after mode imputation:\\n\", sampled_dataset.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fb3df46",
   "metadata": {},
   "source": [
    "### the most useful Independent Variables can be statistically determined using the following methods:\n",
    "\n",
    "1. Univariate Selection\n",
    "2. Feature Importance\n",
    "3. Correlation Matrix with Heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fb68b6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in sampled_dataset.columns:\n",
    "    if sampled_dataset[column].dtype == 'object':\n",
    "        sampled_dataset[column] = sampled_dataset[column].astype('category').cat.codes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11c004de",
   "metadata": {},
   "source": [
    "### Univariate Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78839235",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = sampled_dataset.drop('rating', axis=1)  # Features\n",
    "y = sampled_dataset['rating']  #  'rating' is the target variable\n",
    "bestfeatures = SelectKBest(score_func=chi2, k=10)\n",
    "fit = bestfeatures.fit(X.select_dtypes(include=['number']), y)\n",
    "dfscores = pd.DataFrame(fit.scores_)\n",
    "dfcolumns = pd.DataFrame(X.columns)\n",
    "featureScores = pd.concat([dfcolumns, dfscores], axis=1)\n",
    "featureScores.columns = ['Specs', 'Score']  # naming the dataframe columns\n",
    "\n",
    "univariate_scores = featureScores.nlargest(38, 'Score')\n",
    "univariate_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4985368",
   "metadata": {},
   "source": [
    "### Feature Importance with RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6834def",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Importance\n",
    "model = RandomForestClassifier()\n",
    "model.fit(X, y)\n",
    "importances = model.feature_importances_\n",
    "feature_importances = pd.DataFrame({'feature': X.columns, 'importance': importances})\n",
    "feature_importance_sorted = feature_importances.sort_values('importance', ascending=False)\n",
    "feature_importance_sorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3beb0fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Correlation Matrix with Heatmap\n",
    "\n",
    "corrmat = sampled_dataset.corr()\n",
    "plt.figure(figsize=(25,25))\n",
    "sns.heatmap(corrmat, annot=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90eb0667",
   "metadata": {},
   "source": [
    "From the above all analysis, we can conclude that\n",
    "\n",
    "**In Univariate** \n",
    "This score represents the result of a statistical test that measures the strength of the relationship between each individual feature and the target variable\n",
    "\n",
    "1. Kills\n",
    "2. Deaths\n",
    "3. Headshots\n",
    "4. Gun1 Kills\n",
    "5. Assists\n",
    "6. Gun2 Kills\n",
    "7. Clutches\n",
    "8. First Bloods\n",
    "These features have significantly higher scores compared to the rest.\n",
    "\n",
    "**In Feature Importance**\n",
    "Feature importance is calculated based on the Random Forest model's ability to use these features to reduce impurity\n",
    "\n",
    "1. Win Percent\n",
    "2. Wins\n",
    "3. Headshots\n",
    "4. Kills\n",
    "5. Clutches\n",
    "6. Gun1 Kills\n",
    "7. First Bloods\n",
    "8. Assists\n",
    "There's some overlap between the univariate scores and feature importance results\n",
    "\n",
    "**Correlation Matrix**\n",
    "with looking at Correlation matrix we can see that \n",
    "1. kills\n",
    "2. assists\n",
    "3. deaths\n",
    "4. aces\n",
    "5. flawless\n",
    "6. clutches\n",
    "7. First bloods\n",
    "8. gun1_kills\n",
    "9. kd_ration\n",
    "\n",
    "very correlated wit the target variable. from the above results and Domain knowledge we can use 'kills', 'deaths', 'headshots', 'gun1_kills', 'assists', 'clutches', 'first_bloods', 'win_percent', 'wins', 'aces' features for building a predictive model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4967f64b",
   "metadata": {},
   "source": [
    "## In the predictor variables independent of all the other predictor variables?\n",
    "\n",
    "We can know the correlation between the independent variables from correlation matrix "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a51065e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation_matrix = sampled_dataset.corr()\n",
    "\n",
    "# Define a threshold for strong correlations\n",
    "threshold = 0.95\n",
    "\n",
    "# Find correlated variables\n",
    "correlated_vars = set()\n",
    "for i in range(len(correlation_matrix.columns)):\n",
    "    for j in range(i+1, len(correlation_matrix.columns)):\n",
    "        if abs(correlation_matrix.iloc[i, j]) > threshold:\n",
    "            correlated_vars.add((correlation_matrix.columns[i], correlation_matrix.columns[j]))\n",
    "\n",
    "# Print correlated variable pairs\n",
    "for var_pair in correlated_vars:\n",
    "    print(var_pair)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b43f5af",
   "metadata": {},
   "source": [
    "from the above output we can conclude that many are highly correlated with each other.\n",
    "we need to carefully choose the features which are not very highly correlated among there to reduce multicollinearity.\n",
    "which can affect the performance and interpretability of some predictive models, particularly those that rely on the independence assumption\n",
    "\n",
    "So, lets eleminate some features which we selected previously\n",
    "we can remove 'wins', 'deaths' as they are correlated with many other selected features. \n",
    "\n",
    "## Which predictor variables are the most important?\n",
    "\n",
    "From \n",
    "1. Univariate Selection\n",
    "2. Feature Importance\n",
    "3. Correlation Matrix with Heatmap\n",
    "\n",
    "we could figure out around 9 features which are most important in this dataset\n",
    "**'kills', 'headshots', 'gun1_kills', 'assists', 'clutches', 'first_bloods', 'win_percent', 'aces', 'headshot_percent'**\n",
    "\n",
    "we had to remove some features/ predictor even though they had good scores in Univariate Selection\n",
    "and Feature Importance, due to the multicollinearity.\n",
    "\n",
    "we want to reduce multicollinearity. which can affect the performance and interpretability of some predictive models, particularly those that rely on the independence assumption"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d7ff2a8",
   "metadata": {},
   "source": [
    "## One Hot encoding "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72be05b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_dataset = data.sample(frac=0.2, random_state=1)\n",
    "hf = h2o.H2OFrame(sampled_dataset)\n",
    "categorical_columns = ['agent_1', 'agent_2', 'agent_3', 'gun1_name', 'gun2_name', 'gun3_name']\n",
    "\n",
    "data_encoded = pd.get_dummies(sampled_dataset, columns=categorical_columns, drop_first=True)\n",
    "\n",
    "print(data_encoded.shape)\n",
    "data_encoded.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb031aa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define features (X) and target (y)\n",
    "X = data_encoded.drop('rating', axis=1)  # Drop the target variable to isolate features\n",
    "y = data_encoded['rating']  # Target variable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed7915ad",
   "metadata": {},
   "source": [
    "## H20 AutoML Execution\n",
    "Run AutoML. The max_runtime_secs argument provides a way to limit the AutoML run by time.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "722850ac",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Specify the target column name as a string\n",
    "target = 'rating'  # This should be the name of your target column in 'hf'\n",
    "\n",
    "features = hf.columns\n",
    "features.remove(target)\n",
    "\n",
    "# Initialize and configure AutoML\n",
    "aml = H2OAutoML(max_runtime_secs=300, seed=1)  # Adjust 'max_runtime_secs' as needed\n",
    "\n",
    "# Train the model using the names of the feature and target columns\n",
    "aml.train(x=features, y=target, training_frame=hf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f731483c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(aml.leaderboard)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0583e96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the top model\n",
    "top_model = aml.leader\n",
    "\n",
    "# Print a summary of the top model\n",
    "print(top_model.summary())\n",
    "\n",
    "# For more detailed performance metrics, you can use the model_performance() method\n",
    "performance = top_model.model_performance()\n",
    "\n",
    "# Print out the performance metrics\n",
    "print(performance)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c668149",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the AutoML leaderboard with all metrics\n",
    "lb = h2o.automl.get_leaderboard(aml, extra_columns = \"ALL\")\n",
    "lb.head(rows=lb.nrows)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cae77e74",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ids = list(aml.leaderboard['model_id'].as_data_frame().iloc[:,0])\n",
    "model_ids\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1236e733",
   "metadata": {},
   "outputs": [],
   "source": [
    "for model_id in model_ids:\n",
    "    model = h2o.get_model(model_id)\n",
    "    performance = model.model_performance()  # Use validation_frame if you have it: model.model_performance(valid)\n",
    "    print(f\"Model: {model_id}, R^2: {performance.r2()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3416627",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ids = list(lb['model_id'].as_data_frame().iloc[:,0])\n",
    "\n",
    "# Initialize a dictionary to hold model performance metrics\n",
    "model_performance = {}\n",
    "\n",
    "for model_id in model_ids:\n",
    "    model = h2o.get_model(model_id)\n",
    "    performance = model.model_performance()  # Use test data if available\n",
    "    model_performance[model_id] = {\n",
    "        'R2': performance.r2(),\n",
    "        'RMSE': performance.rmse(),\n",
    "        'MSE': performance.mse()\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6172a879",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the model_performance dictionary to a DataFrame for easier plotting\n",
    "performance_df = pd.DataFrame.from_dict(model_performance, orient='index')\n",
    "\n",
    "# Plot R2 values\n",
    "plt.figure(figsize=(10, 6))\n",
    "performance_df['R2'].plot(kind='bar')\n",
    "plt.title('R^2 Values for Models')\n",
    "plt.ylabel('R^2')\n",
    "plt.xlabel('Model ID')\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4f98c8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the DataFrame with performance metrics\n",
    "print(performance_df[['R2', 'RMSE', 'MSE']])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "352337db",
   "metadata": {},
   "source": [
    "With the provided \\(R^2\\) values for each model from your H2O AutoML leaderboard, let's dive deeper into what these values mean for your question about significance, and how to interpret these results in the context of your assignment.\n",
    "\n",
    "### Understanding \\(R^2\\) (Coefficient of Determination)\n",
    "\n",
    "The \\(R^2\\) value, or coefficient of determination, is a statistical measure that represents the proportion of the variance for the dependent variable that's explained by the independent variables in a regression model. It provides an indication of the goodness of fit of the model and its ability to make predictions.\n",
    "\n",
    "- **\\(R^2 = 1\\)**: Indicates that the regression predictions perfectly fit the data.\n",
    "- **\\(R^2 = 0\\)**: Indicates that the model does not explain any of the variability of the response data around its mean.\n",
    "\n",
    "### Model Significance Based on \\(R^2\\)\n",
    "\n",
    "1. **GBM Models**: The Gradient Boosting Machine (GBM) models show very high \\(R^2\\) values, close to 1 for some models (e.g., `GBM_1_AutoML_2_20240217_170753` with \\(R^2\\) of 0.9992), indicating an excellent fit to the data. This suggests these models are capturing a significant relationship between the features and the target variable.\n",
    "\n",
    "2. **DRF Model**: The Distributed Random Forest (DRF) model also demonstrates a high \\(R^2\\) value (0.9773), signifying that it effectively captures the variability in the target variable.\n",
    "\n",
    "3. **StackedEnsemble Models**: These models, especially the `StackedEnsemble_AllModels_1_AutoML_2_20240217_170753` and `StackedEnsemble_BestOfFamily_1_AutoML_2_20240217_170753` with \\(R^2\\) values of 0.9909 and 0.9967 respectively, show that combining multiple models through ensembling can further enhance the ability to capture significant relationships in the data.\n",
    "\n",
    "4. **GLM Model**: The Generalized Linear Model (GLM) shows a lower \\(R^2\\) value (0.8377) compared to the other models. Although this still indicates a good level of fit, it suggests the GLM may not capture the complexity of the data as effectively as the other models.\n",
    "\n",
    "### Interpreting the Results\n",
    "\n",
    "Given these \\(R^2\\) values, you can conclude that most models generated by AutoML significantly capture the relationship between the independent variables and the dependent variable. The GBM models and StackedEnsemble models, in particular, show exceptional performance, suggesting very strong predictive relationships.\n",
    "\n",
    "stating the \\(R^2\\) value alongside other performance metrics (like RMSE and logloss) for each model will provide a comprehensive view of each model's effectiveness. High \\(R^2\\) values complemented by low error metrics (RMSE, logloss) indicate a model that not only fits the data well but also predicts accurately, thereby highlighting the significance of the relationships it has captured."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da3db13e",
   "metadata": {},
   "source": [
    "## Is the relationship significant?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9b33738",
   "metadata": {},
   "source": [
    "### Understanding Predictor Significance\n",
    "In statistical modeling and machine learning, the significance of predictors is often assessed through their impact on the model's predictive power and whether changes in predictor values lead to significant changes in the outcome variable.\n",
    "\n",
    "For linear models, such as Linear Regression or Generalized Linear Models (GLM), this can be directly interpreted through p-values and coefficients. For more complex models like those typically included in AutoML (e.g., GBM, Random Forest, or Stacked Ensembles), we look at feature importance scores."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69c4c5f0",
   "metadata": {},
   "source": [
    "### Feature Importance: \n",
    "This is a key metric for understanding the significance of predictors in complex models. It tells us how much each feature contributes to the model's predictions. A higher importance score means the predictor has a more significant impact on the prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d988224",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_model = h2o.automl.get_leaderboard(aml, extra_columns = \"ALL\").as_data_frame().iloc[0]['model_id']\n",
    "top_model = h2o.get_model(top_model)\n",
    "#loading the top_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a24ec51",
   "metadata": {},
   "outputs": [],
   "source": [
    "#top model\n",
    "!top_model.varimp_plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2622d03d",
   "metadata": {},
   "source": [
    "Starting from the top:\n",
    "\n",
    "1. **first_bloods**: \n",
    "This feature has the highest importance score among all the features listed, indicating it is the most predictive of player performance according to the model. In gaming terms, \"first bloods\" typically refers to the first kill in a match and may suggest that players who achieve this are likely to perform well overall.\n",
    "\n",
    "2. **headshot_percent**: \n",
    "The second most important feature, \"headshot_percent\", implies that the accuracy of a player, measured by the percentage of kills that are headshots, is also a strong predictor of performance.\n",
    "\n",
    "3. **aces**: \n",
    "Coming in third, \"aces\" might be a term describing a scenario where a single player remarkably outperforms others in a specific round or game segment. Its position indicates a significant impact on the overall prediction of player performance.\n",
    "\n",
    "4. **agent_3** and **agent_2**: \n",
    "These features are likely categorical variables representing different in-game characters, roles, or abilities chosen by players. Their position in the feature importance plot suggests that the choice of these agents has a meaningful impact on performance outcomes.\n",
    "\n",
    "5. **kills**: \n",
    "The number of kills is a straightforward indicator of a player's performance and is expectedly an important feature. It's placed lower than some other features, which could imply that the model is picking up on the fact that raw kill counts are not as predictive as how those kills are achieved (e.g., achieving first bloods or a high headshot percentage).\n",
    "\n",
    "6. **agent_1**: \n",
    "This is another agent-related feature but is deemed less important than \"agent_3\" and \"agent_2\" by the model. This could be due to a variety of reasons, such as overlaps in what these features represent or their correlation with other more important features.\n",
    "\n",
    "7. **headshots**: \n",
    "This feature is likely correlated with \"headshot_percent\" but is less important, potentially due to \"headshot_percent\" providing a normalized measure that accounts for total shots or kills, thus being a better performance indicator.\n",
    "\n",
    "8. **region**: \n",
    "This feature could indicate the geographical or server region of the player. Its importance suggests that regional factors might have some bearing on player performance, which could be due to differences in competitive levels, playstyles, or latency in different regions.\n",
    "\n",
    "9. **wins**: \n",
    "Interestingly, \"wins\" is the least important feature among those listed, which might indicate that while winning is the ultimate goal, the model finds other features to be better early indicators of a player's performance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e321e49",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "classes = hf['rating'].levels()[0]  # Replace 'target_column' with your actual target column name.\n",
    "\n",
    "# Generate partial plots for each class\n",
    "for class_name in classes:\n",
    "    top_model.partial_plot(data=hf, cols=['first_bloods', 'aces', 'headshot_percent'], targets=[class_name], plot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9db72dc7",
   "metadata": {},
   "source": [
    "From the partial plots we can see that the relationship between these predictors and target variable is not a flat line, that means there is a relationship and it also seems very significant for flood_bloods, aces and headshot_percent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbb2f7d4",
   "metadata": {},
   "source": [
    "Flat Curve: If the partial dependence plot is relatively flat across values of the feature, it suggests that the feature has little impact on the prediction. In other words, changes in this feature do not significantly affect the predicted outcome.\n",
    "\n",
    "Sloping Curve (either upwards or downwards): A sloping curve indicates a relationship between the feature and the prediction. An upward slope suggests that as the feature value increases, the predicted outcome also increases. Conversely, a downward slope suggests that as the feature value increases, the predicted outcome decreases."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3200ace2",
   "metadata": {},
   "source": [
    "## to answer our question \"Is the relationship significant?\"\n",
    "\n",
    "YES, from the feature importance plot (varimp_plot) we can see that flood_bloods, aces and headshot_percent hold a significat relationship with rating. this can be confirmed from partial plots of these variables. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf32c307",
   "metadata": {},
   "source": [
    "## Are any model assumptions violated?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2fd6fc2",
   "metadata": {},
   "source": [
    "From the AutoML, we can take the topModel and answer this question. which is a Gradient Boosting Machine (GBM)\n",
    "\n",
    "GBMs, as ensemble tree-based methods, do not rely on the same assumptions as linear models. They do not require that the relationship between the features and target be linear, that the errors be normally distributed, or that the variance of errors be constant across levels of an independent variable (homoscedasticity). Therefore, the traditional assumptions of linearity, homoscedasticity, and normality of residuals do not apply to GBMs.\n",
    "\n",
    "**Feature Interaction**: GBMs assume that interaction between features can be captured through the tree-building process. They do not require features to be independent.\n",
    "\n",
    "**Non-Collinearity**: While GBMs can handle multicollinearity better than linear models, extreme multicollinearity can still lead to issues such as overemphasis on correlated predictors.\n",
    "\n",
    "**Stationarity**: GBMs assume that the relationship between the predictors and the response does not change over time or across different data segments.\n",
    "\n",
    "we can say there are no assumptions violated.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "724ab233",
   "metadata": {},
   "source": [
    "##  Is there any multicollinearity in the model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6af1e117",
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in sampled_dataset.columns:\n",
    "    if sampled_dataset[column].dtype == 'object':\n",
    "        sampled_dataset[column] = sampled_dataset[column].astype('category').cat.codes\n",
    "def calculate_vifs(df):\n",
    "    vif_data = pd.DataFrame()\n",
    "    vif_data['feature'] = df.columns\n",
    "    vif_data['VIF'] = [variance_inflation_factor(df.values, i) for i in range(len(df.columns))]\n",
    "    return vif_data\n",
    "\n",
    "# Calculate VIF for the features, excluding the target variable\n",
    "features_df = sampled_dataset.drop(columns='rating')  # Replace 'target_variable' with your actual target column name\n",
    "vif_df = calculate_vifs(features_df)\n",
    "print(vif_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1506bae",
   "metadata": {},
   "source": [
    "High VIF Values: Signal high multicollinearity that could pose problems for certain types of models, particularly linear models, by inflating the standard errors of the coefficients. Many features in your dataset, such as **damage_round, headshots, clutches, kills, deaths, kd_ratio, kills_round, score_round, and various gun-related features**, exhibit extremely high VIF values, sometimes in the hundreds or even thousands. This suggests these features are highly dependent on each other, which could be due to direct correlations or because they represent different aspects of similar underlying phenomena (e.g., different metrics of player performance).\n",
    "\n",
    "lets drop these features and re-run the AutoML we have better fitted models, see how it goes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a02e15ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_to_drop = [\n",
    "    'damage_round', 'headshots', 'clutches', 'kills', 'deaths',\n",
    "    'kd_ratio', 'kills_round', 'score_round',\n",
    "    'gun1_name', 'gun1_head', 'gun1_body', 'gun1_legs', 'gun1_kills',\n",
    "    'gun2_name', 'gun2_head', 'gun2_body', 'gun2_legs', 'gun2_kills',\n",
    "    'gun3_name', 'gun3_head', 'gun3_body', 'gun3_legs', 'gun3_kills'\n",
    "]\n",
    "\n",
    "# Drop these features from the H2OFrame\n",
    "hf_reduced = hf.drop(features_to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24656f0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = 'rating' \n",
    "\n",
    "features = hf_reduced.columns\n",
    "features.remove(target)\n",
    "\n",
    "aml_red = H2OAutoML(max_runtime_secs=300, seed=1)  \n",
    "\n",
    "aml_red.train(x=features, y=target, training_frame=hf_reduced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b015512d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ids = list(aml_red.leaderboard['model_id'].as_data_frame().iloc[:,0])\n",
    "model_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "500633c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "for model_id in model_ids:\n",
    "    model = h2o.get_model(model_id)\n",
    "    performance = model.model_performance()  # Use validation_frame if you have it: model.model_performance(valid)\n",
    "    print(f\"Model: {model_id}, R^2: {performance.r2()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e76fb11",
   "metadata": {},
   "source": [
    "after removing highly corelated columns, we could see a increase in R^2 but, it is not that significant. because many models can handle some level of multi corelation, so keep or removing these features didn't effect out overall models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b26e2911",
   "metadata": {},
   "source": [
    "## In the multivariate models are predictor variables independent of all the other predictor variables?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76235114",
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in sampled_dataset.columns:\n",
    "    if sampled_dataset[column].dtype == 'object':\n",
    "        sampled_dataset[column] = sampled_dataset[column].astype('category').cat.codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59628cc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "corrmat = sampled_dataset.corr()\n",
    "# Set the font scale and style\n",
    "sns.set(font_scale=0.5, style='whitegrid')\n",
    "\n",
    "# Create a larger figure to fit the smaller text\n",
    "plt.figure(figsize=(25, 25))\n",
    "\n",
    "# Create the heatmap with annotations and decreased annotation font size\n",
    "sns.heatmap(corrmat, annot=True, annot_kws={\"size\": 8})\n",
    "\n",
    "# Show the plot with the adjusted font size\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a74b34cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation_matrix = sampled_dataset.corr()\n",
    "\n",
    "# Define a threshold for strong correlations\n",
    "threshold = 0.95\n",
    "\n",
    "# Find correlated variables\n",
    "correlated_vars = set()\n",
    "for i in range(len(correlation_matrix.columns)):\n",
    "    for j in range(i+1, len(correlation_matrix.columns)):\n",
    "        if abs(correlation_matrix.iloc[i, j]) > threshold:\n",
    "            correlated_vars.add((correlation_matrix.columns[i], correlation_matrix.columns[j]))\n",
    "\n",
    "# Print correlated variable pairs\n",
    "for var_pair in correlated_vars:\n",
    "    print(var_pair)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a6c75f9",
   "metadata": {},
   "source": [
    "Based on the **correlation matrix** and **Variance Inflation Factor (VIF)** analysis, it is evident that certain predictor variables in our dataset exhibit a degree of dependence on one another. This interdependence among predictors can potentially affect the performance of certain statistical models that presume feature independence, such as linear regression. However, AutoML frameworks are equipped to handle a level of multicollinearity and still produce robust models.\n",
    "\n",
    "To mitigate any potential issues and enhance model interpretability, we proactively identified and removed predictors that demonstrated substantial multicollinearity. The AutoML process was then re-run with this refined set of features.\n",
    "\n",
    "The following pairs of predictors were identified as being notably correlated:\n",
    "\n",
    "- Kills and wins, where the number of kills seems to be a strong predictor of the number of wins.\n",
    "- Flawless victories and wins, suggesting that flawless performance is often associated with winning outcomes.\n",
    "- Deaths and wins, indicating a possible inverse relationship where fewer deaths might lead to more wins.\n",
    "- Clutches and deaths, which may reflect the critical moments in gameplay where survival impacts the game's outcome.\n",
    "- Headshots and clutches, as well as headshots and deaths, point to a relationship between precision and critical gameplay moments.\n",
    "- Clutches with both kills and wins, emphasizing the importance of pivotal plays in achieving victory.\n",
    "- Gun-specific statistics such as gun2_head and gun2_body, gun1_head and gun1_body, which are inherently related by nature of the gameplay mechanics.\n",
    "- Kills and deaths, damage_round and score_round, and flawless performance with both deaths and kills, all showcase relationships that are intuitive in the context of the game's dynamics.\n",
    "\n",
    "The removal of these correlated predictors and the subsequent execution of AutoML with a streamlined set of features allow us to focus on the most significant variables. Importantly, the top-performing variables identified by AutoML are largely independent, reinforcing the validity of our model's insights."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86b30e6b",
   "metadata": {},
   "source": [
    "## In in multivariate models rank the most significant predictor variables and exclude insignificant ones from the model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ace4e65e",
   "metadata": {},
   "source": [
    "From feature Importance (varimp plot) we can say that first_bloods, headshot_precent, aces are the most significant predictor.\n",
    "\n",
    "Lets exclude all other features and only keep these from our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f25bb1a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "hf.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a8283a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_to_drop = ['region',\n",
    " 'name',\n",
    " 'tag',\n",
    " 'damage_round',\n",
    " 'headshots',\n",
    " 'clutches',\n",
    " 'flawless',\n",
    " 'kills',\n",
    " 'deaths',\n",
    " 'assists',\n",
    " 'kd_ratio',\n",
    " 'kills_round',\n",
    " 'most_kills',\n",
    " 'score_round',\n",
    " 'wins',\n",
    " 'win_percent',\n",
    " 'agent_1',\n",
    " 'agent_2',\n",
    " 'agent_3',\n",
    " 'gun1_name',\n",
    " 'gun1_head',\n",
    " 'gun1_body',\n",
    " 'gun1_legs',\n",
    " 'gun1_kills',\n",
    " 'gun2_name',\n",
    " 'gun2_head',\n",
    " 'gun2_body',\n",
    " 'gun2_legs',\n",
    " 'gun2_kills',\n",
    " 'gun3_name',\n",
    " 'gun3_head',\n",
    " 'gun3_body',\n",
    " 'gun3_legs',\n",
    " 'gun3_kills']\n",
    "\n",
    "# Drop these features from the H2OFrame\n",
    "hf_significant = hf.drop(features_to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41e90cd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = 'rating' \n",
    "\n",
    "features = hf_significant.columns\n",
    "features.remove(target)\n",
    "\n",
    "aml_sig = H2OAutoML(max_runtime_secs=300, seed=1)  \n",
    "\n",
    "aml_sig.train(x=features, y=target, training_frame=hf_significant)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88ad28bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the top model\n",
    "top_model = aml_sig.leader\n",
    "\n",
    "# Print a summary of the top model\n",
    "print(top_model.summary())\n",
    "\n",
    "# For more detailed performance metrics, you can use the model_performance() method\n",
    "performance = top_model.model_performance()\n",
    "\n",
    "# Print out the performance metrics\n",
    "print(performance)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e7a5b69",
   "metadata": {},
   "source": [
    "The initial model summary showcases a GBM with good performance metrics, as evidenced by a lower MSE of 0.0070 and RMSE of 0.0839, suggesting a tight fit to the training data. The Mean Per-Class Error is notably low at 0.0952, indicating accuracy across classes.\n",
    "\n",
    "Post feature reduction, the DRF model exhibits higher error metrics, with MSE increasing to 0.0204 and RMSE to 0.1429, reflecting reduced accuracy. The Mean Per-Class Error also rises significantly to 0.5991, pointing to decreased predictive consistency across classes.\n",
    "\n",
    "In essence, the feature reduction appears to have diminished the model's ability to accurately predict outcomes, as crucial information may have been lost when correlated predictors were removed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef5ef00f",
   "metadata": {},
   "source": [
    "## Does the model make sense?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ec66623",
   "metadata": {},
   "source": [
    "Yes, From our analysis GBM is the best model, modeling is done after removing the highly multi-correlated predictor has the best metrics\n",
    "\n",
    "the GBM model emerges as the optimal model post-elimination of highly multicollinear predictors. It exhibits outstanding training performance, reflected by the following metrics:\n",
    "\n",
    "MSE: 0.0006279336945766971\n",
    "RMSE: 0.025058605200144263\n",
    "LogLoss: 0.0058496757685480285\n",
    "Mean Per-Class Error: 0.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df3a92d5",
   "metadata": {},
   "source": [
    "## Does regularization help?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd3aeadd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import h2o\n",
    "from h2o.estimators.gbm import H2OGradientBoostingEstimator\n",
    "\n",
    "\n",
    "# Assuming 'hf_reduced' is your H2OFrame with the dataset already loaded into H2O\n",
    "predictors = hf_reduced.columns\n",
    "predictors.remove('rating')\n",
    "response = 'rating' # target variable\n",
    "\n",
    "# Initialize the GBM model with regularization parameters\n",
    "gbm_model_with_regularization = H2OGradientBoostingEstimator(\n",
    "    ntrees=100,\n",
    "    learn_rate=0.1,\n",
    "    max_depth=5,\n",
    "    sample_rate=0.8,\n",
    "    col_sample_rate_per_tree=0.8,\n",
    "    nfolds=5,\n",
    "    fold_assignment=\"Modulo\",\n",
    "    keep_cross_validation_predictions=True,\n",
    "    seed=1234\n",
    ")\n",
    "\n",
    "# Train the GBM model using cross-validation\n",
    "gbm_model_with_regularization.train(x=predictors, y=response, training_frame=hf_reduced)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c41c0e4a",
   "metadata": {},
   "source": [
    "The application of regularization techniques in the Gradient Boosting Machine (GBM) model aimed to improve its generalization ability by reducing overfitting. Regularization was implemented by adjusting the `sample_rate` and `col_sample_rate_per_tree`, simulating the effects of Ridge (L2) and Lasso (L1) regularization, respectively. These adjustments influence the model by controlling the fraction of data and features used for building each tree, encouraging the model to focus on the most relevant patterns and potentially reducing the impact of noise.\n",
    "\n",
    "**Before Regularization:**\n",
    "- **Cross-Validation Data Metrics:**\n",
    "  - MSE: 0.014256829641964364\n",
    "  - RMSE: 0.11940196665869605\n",
    "  - LogLoss: 0.055769949393464566\n",
    "  - Mean Per-Class Error: 0.47567316568112666\n",
    "\n",
    "**After Regularization:**\n",
    "- **Cross-Validation Data Metrics:**\n",
    "  - MSE: 0.014035510216891919 (Slightly Lower)\n",
    "  - RMSE: 0.1184715586834744 (Slightly Lower)\n",
    "  - LogLoss: 0.05597866068626825 (Slightly Higher)\n",
    "  - Mean Per-Class Error: 0.4887788941579695 (Slightly Higher)\n",
    "\n",
    "**Analysis:**\n",
    "After applying regularization, the MSE and RMSE on the cross-validation data show a slight improvement, indicating a marginal increase in the model's prediction accuracy. However, the LogLoss has slightly increased, and the Mean Per-Class Error has also risen, suggesting that the model's average error across all classes has increased. These mixed results imply that while regularization helped in slightly improving the model's fit to the data, it may have also introduced a slight increase in classification error for some classes.\n",
    "\n",
    "Regularization is used to prevent the model from fitting too closely to the training data, which can lead to overfitting and poor performance on unseen data. In this case, the regularization parameters (`sample_rate` and `col_sample_rate_per_tree`) were intended to make the model more robust by reducing the complexity of the trees and ensuring they do not rely too heavily on any single feature or small set of features.\n",
    "\n",
    "**Conclusion:**\n",
    "The effect of regularization on the GBM model shows the delicate balance between reducing overfitting and maintaining classification accuracy across all classes. The slight improvements in MSE and RMSE indicate a positive direction, but the increase in LogLoss and Mean Per-Class Error calls for a more nuanced approach to regularization parameter tuning. It suggests that further experimentation with these parameters, possibly alongside other model hyperparameters, could help in finding a more optimal balance that maximizes model performance while minimizing overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fc6f3d9",
   "metadata": {},
   "source": [
    "## Which independent variables are significant?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce67ea9b",
   "metadata": {},
   "source": [
    "From the variable importance plot from an H2O Gradient Boosting Machine model shows the relative importance of predictor variables in the model. Based on the plot:\n",
    "\n",
    "The most significant independent variables, meaning those that have the most substantial impact on the model's predictions, are as follows:\n",
    "\n",
    "- `first_bloods`\n",
    "- `headshot_percent`\n",
    "- `aces`\n",
    "\n",
    "These variables stand out with the highest importance scores, indicating that they are key drivers of the model's predictions. Variables such as `agent_3`, `agent_2`, and `kills` also appear on the plot but with less importance compared to the top variables.\n",
    "\n",
    "In summary, the variables `first_bloods`, `headshot_percent`, and `aces` are the most significant independent variables in the model according to the variable importance plot."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7e79aea",
   "metadata": {},
   "source": [
    "## Which hyperparameters are important?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "992f1e9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_model = aml.leader\n",
    "model_id = top_model.model_id\n",
    "model_details = h2o.get_model(model_id)\n",
    "\n",
    "# Print the hyperparameters of the model\n",
    "print(model_details.params)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51c443d3",
   "metadata": {},
   "source": [
    "The output lists various hyperparameters used by an H2O Gradient Boosting Machine model along with their default, actual, and input values. To identify the most important hyperparameters and potential areas for improvement, we can look at:\n",
    "\n",
    "1. **Deviation from Defaults**: Hyperparameters where the actual values differ significantly from the defaults may have been chosen by the AutoML process as influential for model performance.\n",
    "\n",
    "2. **User Input**: Hyperparameters where the input values differ from the defaults suggest deliberate tuning, indicating these parameters may be crucial to model outcomes.\n",
    "\n",
    "From the provided output, several hyperparameters stand out:\n",
    "\n",
    "- `ntrees`: The number of trees used is 55, higher than the default of 50, and less than the input of 10,000. This suggests the model stopped building trees well before reaching the input maximum, likely due to early stopping criteria.\n",
    "\n",
    "- `max_depth`: The maximum depth of each tree is 8, higher than the default of 5, which allows the model to capture more complex patterns.\n",
    "\n",
    "- `sample_rate` and `col_sample_rate`: Both are set at 0.8 instead of the default 1.0, indicating that each tree is built on 80% of the data and features. This helps in preventing overfitting.\n",
    "\n",
    "- `stopping_metric` and `stopping_tolerance`: These are set to 'logloss' and approximately 0.0076, respectively, indicating that the model's training stopped when the log loss did not improve by this tolerance.\n",
    "\n",
    "To potentially improve the model, you could consider adjusting these hyperparameters:\n",
    "\n",
    "- `ntrees`: Increase if the model is underfitting or decrease if overfitting.\n",
    "\n",
    "- `max_depth`: Decrease if the model is overfitting; increase to capture more complex relationships if underfitting.\n",
    "\n",
    "- `sample_rate` and `col_sample_rate`: Adjust to see if a different proportion of data/features per tree improves the model.\n",
    "\n",
    "- `stopping_tolerance`: A smaller value may lead to more extended training and potentially better performance, at the cost of longer training time.\n",
    "\n",
    "To change and test the hyperparameters, you can manually specify them in the H2OAutoML or H2O GBM settings when initializing the model. lets adjust `max_depth` and `ntrees`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36c6763c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from h2o.estimators.gbm import H2OGradientBoostingEstimator\n",
    "\n",
    "# Specify the hyperparameters\n",
    "gbm_params = {\n",
    "    'ntrees': 100,  # Increase the number of trees\n",
    "    'max_depth': 6,  # Slightly decrease the tree depth\n",
    "    'sample_rate': 0.8,\n",
    "    'col_sample_rate': 0.8,\n",
    "    'stopping_metric': 'logloss',\n",
    "    'stopping_tolerance': 0.001,  # Smaller stopping tolerance\n",
    "    'seed': 6  # Keep the seed for reproducibility\n",
    "}\n",
    "\n",
    "# Initialize and train the GBM model with specified hyperparameters\n",
    "gbm_model = H2OGradientBoostingEstimator(**gbm_params)\n",
    "gbm_model.train(y=target, training_frame=hf_reduced)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bbb8afe",
   "metadata": {},
   "source": [
    "After adjusting the hyperparameters, the model's performance on the training data has improved significantly:\n",
    "\n",
    "**Before Hyperparameter Adjustment:**\n",
    "- MSE: 0.0006279336945766971\n",
    "- RMSE: 0.025058605200144263\n",
    "- LogLoss: 0.0058496757685480285\n",
    "\n",
    "**After Hyperparameter Adjustment:**\n",
    "- MSE: 0.0001368164284168679 (approximately 4.6 times lower)\n",
    "- RMSE: 0.011696855492689815 (over 2 times lower)\n",
    "- LogLoss: 0.0024950665531210873 (more than 2 times lower)\n",
    "\n",
    "The Mean Per-Class Error remains at 0.0 for both models, indicating perfect classification accuracy on the training data in both cases.\n",
    "\n",
    "The reduction in MSE, RMSE, and LogLoss suggests that the model is fitting the training data even better after hyperparameter tuning and is likely capturing the underlying patterns more effectively. However, it's essential to validate these results on a hold-out set or through cross-validation to ensure that the model has not overfitted to the training data and can generalize well to unseen data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0ddb0b1",
   "metadata": {},
   "source": [
    "References:\n",
    "\n",
    "1. Jain, A. (2024, January 11). Ridge and lasso regression in Python | Complete tutorial (Updated 2024). Analytics Vidhya. https://www.analyticsvidhya.com/blog/2016/01/ridge-lasso-regression-python-complete-tutorial/ \n",
    "\n",
    "2. H2O AutoML: Automatic Machine Learning  H2O 3.44.0.3 documentation. (n.d.). https://docs.h2o.ai/h2o/latest-stable/h2o-docs/automl.html\n",
    "\n",
    "3. Team, I. (2023, October 1). Variance Inflation Factor (VIF). Investopedia. https://www.investopedia.com/terms/v/variance-inflation-factor.asp\n",
    "\n",
    "4. Aiskunks. (n.d.). YouTube/A_Crash_Course_in_Statistical_Learning/AutoML/AutoML_Wine_Quality.ipynb at main  aiskunks/YouTube. GitHub. https://github.com/aiskunks/YouTube/blob/main/A_Crash_Course_in_Statistical_Learning/AutoML/AutoML_Wine_Quality.ipynb\n",
    "\n",
    "Licences:\n",
    "    \n",
    "1. impyute 3.7 by Elton Law https://impyute.readthedocs.io/en/master/user_guide/getting_started.html#versions\n",
    "    \n",
    "2. Pandas 1.4 https://pandas.pydata.org/docs/getting_started/overview.html\n",
    "    \n",
    "3. Scipy.stats https://docs.scipy.org/doc/scipy/reference/stats.html\n",
    "    \n",
    "4. sklearn.simpleimputer https://scikit-learn.org/stable/modules/generated/sklearn.impute.SimpleImputer.html\n",
    "    \n",
    "5. sklearn.LinearRegression, GridSearch https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html\n",
    "    \n",
    "6. Valorant Leaderboard Statistics https://www.kaggle.com/datasets/aliibrahim10/valorant-stats\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "370c9c1e",
   "metadata": {},
   "source": [
    "MIT License\n",
    "\n",
    "Copyright (c) 2024 MukulSaiPendem\n",
    "\n",
    "Permission is hereby granted, free of charge, to any person obtaining a copy\n",
    "of this software and associated documentation files (the \"Software\"), to deal\n",
    "in the Software without restriction, including without limitation the rights\n",
    "to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n",
    "copies of the Software, and to permit persons to whom the Software is\n",
    "furnished to do so, subject to the following conditions:\n",
    "\n",
    "The above copyright notice and this permission notice shall be included in all\n",
    "copies or substantial portions of the Software.\n",
    "\n",
    "THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n",
    "IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n",
    "FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n",
    "AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n",
    "LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n",
    "OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\n",
    "SOFTWARE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68f50c81",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
